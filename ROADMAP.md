# Deep Learning From Scratch: Roadmap ğŸ—ºï¸

This roadmap aims to outline the progression and milestones we aim to achieve in building neural network models and deep learning architectures completely from scratch.

## ğŸ¯ **Goals**:
- To understand the intricacies of deep learning algorithms at a granular level.
- Develop implementations free from dependencies on popular deep learning frameworks.
- Foster a community-driven effort for learning and understanding deep learning.

## ğŸ” **Current Progress**:
- [x] Basic data pre-processing without relying on `numpy` or `pandas`.
- [x] Implementation of the Perceptron algorithm.

## ğŸ“ˆ **Upcoming Milestones**:

### **1. Multi-Layer Perceptrons (MLPs) ğŸŒ**:
- [ ] Implement forward and backward propagation.
- [ ] Implement popular activation functions: Sigmoid, ReLU, Tanh, etc.
- [ ] Add support for multiple hidden layers.
- [ ] Introduce gradient descent and backpropagation for weight updates.
  
### **2. Convolutional Neural Networks (CNNs) ğŸ–¼ï¸**:
- [ ] Develop convolutional layers with forward and backward passes.
- [ ] Pooling layers and techniques (Max pooling, Average pooling).
- [ ] Advanced architectures (like LeNet, AlexNet).

### **3. Recurrent Neural Networks (RNNs) ğŸ”„**:
- [ ] Basic RNN implementation.
- [ ] Handling sequences and time-series data.
- [ ] Introduction of LSTM and GRU.

### **4. Advanced Architectures and Techniques ğŸ”®**:
- [ ] Implementing dropout for regularization.
- [ ] Batch normalization.
- [ ] Advanced architectures (like VGG, ResNet, Transformer).

### **5. Optimizers and Loss Functions âš–ï¸**:
- [ ] Gradient descent variations: Momentum, RMSprop, Adam.
- [ ] Different loss functions: Mean squared error, Cross-entropy, Hinge loss.

### **6. Utility Features and Improvements ğŸ› ï¸**:
- [ ] Batch training support.
- [ ] Model saving and loading.
- [ ] Hyperparameter tuning utilities.

## ğŸ¤² **Contribute**:
We welcome contributors of all skill levels to join in this endeavor. Whether it's optimizing a piece of code, suggesting improvements, or fixing bugs, every bit helps!

## ğŸŒ **Resources**:
It's essential to have good reference materials and resources. We aim to maintain a list of books, papers, and articles that have been particularly insightful throughout this journey. (Coming soon!)
