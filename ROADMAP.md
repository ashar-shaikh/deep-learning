# Deep Learning From Scratch: Roadmap 🗺️

This roadmap aims to outline the progression and milestones we aim to achieve in building neural network models and deep learning architectures completely from scratch.

## 🎯 **Goals**:
- To understand the intricacies of deep learning algorithms at a granular level.
- Develop implementations free from dependencies on popular deep learning frameworks.
- Foster a community-driven effort for learning and understanding deep learning.

## 🔍 **Current Progress**:
- [x] Basic data pre-processing without relying on `numpy` or `pandas`.
- [x] Implementation of the Perceptron algorithm.

## 📈 **Upcoming Milestones**:

### **1. Multi-Layer Perceptrons (MLPs) 🌐**:
- [ ] Implement forward and backward propagation.
- [ ] Implement popular activation functions: Sigmoid, ReLU, Tanh, etc.
- [ ] Add support for multiple hidden layers.
- [ ] Introduce gradient descent and backpropagation for weight updates.
  
### **2. Convolutional Neural Networks (CNNs) 🖼️**:
- [ ] Develop convolutional layers with forward and backward passes.
- [ ] Pooling layers and techniques (Max pooling, Average pooling).
- [ ] Advanced architectures (like LeNet, AlexNet).

### **3. Recurrent Neural Networks (RNNs) 🔄**:
- [ ] Basic RNN implementation.
- [ ] Handling sequences and time-series data.
- [ ] Introduction of LSTM and GRU.

### **4. Advanced Architectures and Techniques 🔮**:
- [ ] Implementing dropout for regularization.
- [ ] Batch normalization.
- [ ] Advanced architectures (like VGG, ResNet, Transformer).

### **5. Optimizers and Loss Functions ⚖️**:
- [ ] Gradient descent variations: Momentum, RMSprop, Adam.
- [ ] Different loss functions: Mean squared error, Cross-entropy, Hinge loss.

### **6. Utility Features and Improvements 🛠️**:
- [ ] Batch training support.
- [ ] Model saving and loading.
- [ ] Hyperparameter tuning utilities.

## 🤲 **Contribute**:
We welcome contributors of all skill levels to join in this endeavor. Whether it's optimizing a piece of code, suggesting improvements, or fixing bugs, every bit helps!

## 🌐 **Resources**:
It's essential to have good reference materials and resources. We aim to maintain a list of books, papers, and articles that have been particularly insightful throughout this journey. (Coming soon!)
